{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multi-Layer Perceptron (MLP) - In Search of Optimal Architecture\n",
    "\n",
    "\n",
    "In this notebook we investigate the following two issues related to the MLP/ANN architecture:\n",
    "\n",
    "- How many hidden layers should we use?\n",
    "- How many neurons should we use in each of those layers?\n",
    "\n",
    "Our goal is to understand how to determine the **optimal or near-optimal architecture** for a MLP.\n",
    "\n",
    "We use the MNIST dataset to address these two questions.\n",
    "\n",
    "There are other pertinent issues related to MLP architecture that we could have addressed. For example, what is the optimal activation function (logistic/relu/tanh), what is the best solver (momentum/adam), etc.\n",
    "\n",
    "However, in this notebook we limit our attention to the questions related to #hidden layers and #neurons.\n",
    "\n",
    "Based on prior experimentation, we used 'relu' as the activation function and 'adam' as the optimizer for Gradient Descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: MNIST\n",
    "\n",
    "\n",
    "We will use the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents.\n",
    "\n",
    "\n",
    "There are 70,000 images. Each image is 28x28 pixels, and each feature simply represents one pixelâ€™s intensity, from 0 (white) to 255 (black).\n",
    "\n",
    "Thus, each image has 784 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Data Matrix (X) and the Label Vector (y)\n",
    "\n",
    "First load the data and explore the feature names, target names, etc.\n",
    "\n",
    "We may load the data from a local folder or load it directly from cloud using Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of Samples:  (70000, 784)\n",
      "No. of Labels:  (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the local folder \"data\"\n",
    "mnist = loadmat('data/mnist-original.mat')\n",
    "\n",
    "#Create the data Matrix X and the target vector y\n",
    "X = mnist[\"data\"].T.astype('float64')\n",
    "y = mnist[\"label\"][0].astype('int64')\n",
    "\n",
    "# Load data using Scikit-Learn\n",
    "# mnist = fetch_openml('mnist_784', cache=False)\n",
    "\n",
    "# X = mnist[\"data\"].astype('float64')\n",
    "# y = mnist[\"target\"].astype('int64')\n",
    "\n",
    "print(\"\\nNo. of Samples: \", X.shape)\n",
    "print(\"No. of Labels: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (56000, 784)\n",
      "X_test:  (14000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Architecture\n",
    "\n",
    "We use the following 14 architectures (by varying no. of hidden layers and no. of neurons) to compare their performance (test accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>(200, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>(200, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>(300, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>(300, 200, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>(400, 300, 200, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>(500, 400, 300, 200, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>(1000, 500, 400, 300, 200, 100)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hidden Layers                          Neurons\n",
       "0               1                              100\n",
       "1               1                              200\n",
       "2               1                              500\n",
       "3               1                             1000\n",
       "4               1                             2000\n",
       "5               1                             5000\n",
       "6               2                       (200, 100)\n",
       "7               2                       (200, 200)\n",
       "8               2                       (300, 200)\n",
       "9               3                  (300, 200, 100)\n",
       "10              3                  (200, 200, 200)\n",
       "11              4             (400, 300, 200, 100)\n",
       "12              5        (500, 400, 300, 200, 100)\n",
       "13              6  (1000, 500, 400, 300, 200, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 100],\n",
    "        [1, 200],\n",
    "        [1, 500],\n",
    "        [1, 1000],\n",
    "        [1, 2000],\n",
    "        [1, 5000],\n",
    "        [2, (200, 100)],\n",
    "        [2, (200, 200)],\n",
    "        [2, (300, 200)],\n",
    "        [3, (300, 200, 100)],\n",
    "        [3, (200, 200, 200)],\n",
    "        [4, (400, 300, 200, 100)],\n",
    "        [5, (500, 400, 300, 200, 100)],\n",
    "        [6, (1000, 500, 400, 300, 200, 100)]]\n",
    "pd.DataFrame(data, columns=[\"Hidden Layers\", \"Neurons\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47920562\n",
      "Validation score: 0.918393\n",
      "Iteration 2, loss = 0.22648602\n",
      "Validation score: 0.949643\n",
      "Iteration 3, loss = 0.17103871\n",
      "Validation score: 0.960179\n",
      "Iteration 4, loss = 0.13810706\n",
      "Validation score: 0.965893\n",
      "Iteration 5, loss = 0.11742718\n",
      "Validation score: 0.966607\n",
      "Iteration 6, loss = 0.10230845\n",
      "Validation score: 0.971429\n",
      "Iteration 7, loss = 0.09025462\n",
      "Validation score: 0.971786\n",
      "Iteration 8, loss = 0.08193190\n",
      "Validation score: 0.975357\n",
      "Iteration 9, loss = 0.07368440\n",
      "Validation score: 0.971607\n",
      "Iteration 10, loss = 0.06764236\n",
      "Validation score: 0.976071\n",
      "Iteration 11, loss = 0.06192520\n",
      "Validation score: 0.974821\n",
      "Iteration 12, loss = 0.05745766\n",
      "Validation score: 0.978036\n",
      "Iteration 13, loss = 0.05276187\n",
      "Validation score: 0.976071\n",
      "Iteration 14, loss = 0.05004085\n",
      "Validation score: 0.976250\n",
      "Iteration 15, loss = 0.04673007\n",
      "Validation score: 0.976071\n",
      "Iteration 16, loss = 0.04411568\n",
      "Validation score: 0.977857\n",
      "Iteration 17, loss = 0.04131536\n",
      "Validation score: 0.978214\n",
      "Iteration 18, loss = 0.04014322\n",
      "Validation score: 0.978929\n",
      "Iteration 19, loss = 0.03802863\n",
      "Validation score: 0.977679\n",
      "Iteration 20, loss = 0.03581638\n",
      "Validation score: 0.978571\n",
      "Iteration 21, loss = 0.03496218\n",
      "Validation score: 0.976071\n",
      "Iteration 22, loss = 0.03369885\n",
      "Validation score: 0.976786\n",
      "Iteration 23, loss = 0.03227622\n",
      "Validation score: 0.978036\n",
      "Iteration 24, loss = 0.03144409\n",
      "Validation score: 0.978214\n",
      "Iteration 25, loss = 0.03065451\n",
      "Validation score: 0.978214\n",
      "Iteration 26, loss = 0.03001637\n",
      "Validation score: 0.978036\n",
      "Iteration 27, loss = 0.02940747\n",
      "Validation score: 0.979464\n",
      "Iteration 28, loss = 0.02889768\n",
      "Validation score: 0.979286\n",
      "Iteration 29, loss = 0.02922028\n",
      "Validation score: 0.978214\n",
      "Iteration 30, loss = 0.02732531\n",
      "Validation score: 0.975179\n",
      "Iteration 31, loss = 0.02757617\n",
      "Validation score: 0.977143\n",
      "Iteration 32, loss = 0.02635495\n",
      "Validation score: 0.976964\n",
      "Iteration 33, loss = 0.02660216\n",
      "Validation score: 0.978393\n",
      "Iteration 34, loss = 0.02684406\n",
      "Validation score: 0.978036\n",
      "Iteration 35, loss = 0.02567150\n",
      "Validation score: 0.979107\n",
      "Iteration 36, loss = 0.02575701\n",
      "Validation score: 0.978214\n",
      "Iteration 37, loss = 0.02620995\n",
      "Validation score: 0.979643\n",
      "Iteration 38, loss = 0.02503880\n",
      "Validation score: 0.977857\n",
      "Iteration 39, loss = 0.02465059\n",
      "Validation score: 0.979107\n",
      "Iteration 40, loss = 0.02421558\n",
      "Validation score: 0.978036\n",
      "Iteration 41, loss = 0.02474620\n",
      "Validation score: 0.979286\n",
      "Iteration 42, loss = 0.02574495\n",
      "Validation score: 0.978214\n",
      "Iteration 43, loss = 0.02551402\n",
      "Validation score: 0.979821\n",
      "Iteration 44, loss = 0.02389269\n",
      "Validation score: 0.978393\n",
      "Iteration 45, loss = 0.02387139\n",
      "Validation score: 0.978750\n",
      "Iteration 46, loss = 0.02388507\n",
      "Validation score: 0.980714\n",
      "Iteration 47, loss = 0.02418244\n",
      "Validation score: 0.976250\n",
      "Iteration 48, loss = 0.02409534\n",
      "Validation score: 0.976429\n",
      "Iteration 49, loss = 0.02301416\n",
      "Validation score: 0.979821\n",
      "Iteration 50, loss = 0.02275926\n",
      "Validation score: 0.979107\n",
      "Iteration 51, loss = 0.02758553\n",
      "Validation score: 0.978750\n",
      "Iteration 52, loss = 0.02561888\n",
      "Validation score: 0.978929\n",
      "Iteration 53, loss = 0.02227895\n",
      "Validation score: 0.980179\n",
      "Iteration 54, loss = 0.02154136\n",
      "Validation score: 0.980714\n",
      "Iteration 55, loss = 0.02160726\n",
      "Validation score: 0.980714\n",
      "Iteration 56, loss = 0.02421231\n",
      "Validation score: 0.979107\n",
      "Iteration 57, loss = 0.02385803\n",
      "Validation score: 0.979286\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate='constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.998\n",
      "\n",
      "Test Accuracy:  0.9770714285714286\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_100 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_100)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_100 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40886675\n",
      "Validation score: 0.932679\n",
      "Iteration 2, loss = 0.19419106\n",
      "Validation score: 0.951429\n",
      "Iteration 3, loss = 0.14385625\n",
      "Validation score: 0.960000\n",
      "Iteration 4, loss = 0.11466252\n",
      "Validation score: 0.964464\n",
      "Iteration 5, loss = 0.09499003\n",
      "Validation score: 0.965714\n",
      "Iteration 6, loss = 0.08248333\n",
      "Validation score: 0.970357\n",
      "Iteration 7, loss = 0.07131126\n",
      "Validation score: 0.970179\n",
      "Iteration 8, loss = 0.06324839\n",
      "Validation score: 0.972500\n",
      "Iteration 9, loss = 0.05644300\n",
      "Validation score: 0.973929\n",
      "Iteration 10, loss = 0.05160096\n",
      "Validation score: 0.973571\n",
      "Iteration 11, loss = 0.04799070\n",
      "Validation score: 0.975179\n",
      "Iteration 12, loss = 0.04425474\n",
      "Validation score: 0.976786\n",
      "Iteration 13, loss = 0.04104076\n",
      "Validation score: 0.975893\n",
      "Iteration 14, loss = 0.03763602\n",
      "Validation score: 0.976786\n",
      "Iteration 15, loss = 0.03603052\n",
      "Validation score: 0.977321\n",
      "Iteration 16, loss = 0.03457569\n",
      "Validation score: 0.976786\n",
      "Iteration 17, loss = 0.03249957\n",
      "Validation score: 0.977143\n",
      "Iteration 18, loss = 0.03181334\n",
      "Validation score: 0.975714\n",
      "Iteration 19, loss = 0.02977752\n",
      "Validation score: 0.975714\n",
      "Iteration 20, loss = 0.02978653\n",
      "Validation score: 0.978571\n",
      "Iteration 21, loss = 0.02934286\n",
      "Validation score: 0.976607\n",
      "Iteration 22, loss = 0.02795728\n",
      "Validation score: 0.977143\n",
      "Iteration 23, loss = 0.02738316\n",
      "Validation score: 0.978571\n",
      "Iteration 24, loss = 0.02670965\n",
      "Validation score: 0.979107\n",
      "Iteration 25, loss = 0.02619358\n",
      "Validation score: 0.978750\n",
      "Iteration 26, loss = 0.02819997\n",
      "Validation score: 0.978393\n",
      "Iteration 27, loss = 0.02621332\n",
      "Validation score: 0.978929\n",
      "Iteration 28, loss = 0.02589854\n",
      "Validation score: 0.978929\n",
      "Iteration 29, loss = 0.02502447\n",
      "Validation score: 0.977500\n",
      "Iteration 30, loss = 0.02709255\n",
      "Validation score: 0.979107\n",
      "Iteration 31, loss = 0.02559986\n",
      "Validation score: 0.977679\n",
      "Iteration 32, loss = 0.02471329\n",
      "Validation score: 0.977679\n",
      "Iteration 33, loss = 0.02488966\n",
      "Validation score: 0.978036\n",
      "Iteration 34, loss = 0.02586494\n",
      "Validation score: 0.978036\n",
      "Iteration 35, loss = 0.02418881\n",
      "Validation score: 0.980000\n",
      "Iteration 36, loss = 0.02528651\n",
      "Validation score: 0.978036\n",
      "Iteration 37, loss = 0.02552080\n",
      "Validation score: 0.977679\n",
      "Iteration 38, loss = 0.02560515\n",
      "Validation score: 0.978214\n",
      "Iteration 39, loss = 0.02353292\n",
      "Validation score: 0.978571\n",
      "Iteration 40, loss = 0.02260024\n",
      "Validation score: 0.980179\n",
      "Iteration 41, loss = 0.02229075\n",
      "Validation score: 0.974286\n",
      "Iteration 42, loss = 0.02787461\n",
      "Validation score: 0.975536\n",
      "Iteration 43, loss = 0.02727729\n",
      "Validation score: 0.980893\n",
      "Iteration 44, loss = 0.02311337\n",
      "Validation score: 0.979464\n",
      "Iteration 45, loss = 0.02140246\n",
      "Validation score: 0.978750\n",
      "Iteration 46, loss = 0.02081665\n",
      "Validation score: 0.980893\n",
      "Iteration 47, loss = 0.02203741\n",
      "Validation score: 0.975714\n",
      "Iteration 48, loss = 0.02600482\n",
      "Validation score: 0.975714\n",
      "Iteration 49, loss = 0.02760327\n",
      "Validation score: 0.978214\n",
      "Iteration 50, loss = 0.02318629\n",
      "Validation score: 0.981071\n",
      "Iteration 51, loss = 0.02097697\n",
      "Validation score: 0.981607\n",
      "Iteration 52, loss = 0.02021470\n",
      "Validation score: 0.980714\n",
      "Iteration 53, loss = 0.02073017\n",
      "Validation score: 0.976964\n",
      "Iteration 54, loss = 0.02944007\n",
      "Validation score: 0.978214\n",
      "Iteration 55, loss = 0.02511713\n",
      "Validation score: 0.980357\n",
      "Iteration 56, loss = 0.02220720\n",
      "Validation score: 0.981964\n",
      "Iteration 57, loss = 0.02025180\n",
      "Validation score: 0.981250\n",
      "Iteration 58, loss = 0.02004214\n",
      "Validation score: 0.981071\n",
      "Iteration 59, loss = 0.02032944\n",
      "Validation score: 0.980357\n",
      "Iteration 60, loss = 0.02488881\n",
      "Validation score: 0.979107\n",
      "Iteration 61, loss = 0.02380974\n",
      "Validation score: 0.979821\n",
      "Iteration 62, loss = 0.02337795\n",
      "Validation score: 0.979107\n",
      "Iteration 63, loss = 0.02235670\n",
      "Validation score: 0.979821\n",
      "Iteration 64, loss = 0.02121105\n",
      "Validation score: 0.981071\n",
      "Iteration 65, loss = 0.02151153\n",
      "Validation score: 0.981607\n",
      "Iteration 66, loss = 0.02084608\n",
      "Validation score: 0.979286\n",
      "Iteration 67, loss = 0.02106053\n",
      "Validation score: 0.979821\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 3min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(200,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9981428571428571\n",
      "\n",
      "Test Accuracy:  0.9808571428571429\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_200 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_200)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_200 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.34828794\n",
      "Validation score: 0.951964\n",
      "Iteration 2, loss = 0.15723136\n",
      "Validation score: 0.971250\n",
      "Iteration 3, loss = 0.11277818\n",
      "Validation score: 0.974821\n",
      "Iteration 4, loss = 0.08861000\n",
      "Validation score: 0.978393\n",
      "Iteration 5, loss = 0.07325503\n",
      "Validation score: 0.980536\n",
      "Iteration 6, loss = 0.06225991\n",
      "Validation score: 0.980357\n",
      "Iteration 7, loss = 0.05350172\n",
      "Validation score: 0.982857\n",
      "Iteration 8, loss = 0.04898891\n",
      "Validation score: 0.981071\n",
      "Iteration 9, loss = 0.04400116\n",
      "Validation score: 0.981964\n",
      "Iteration 10, loss = 0.04021121\n",
      "Validation score: 0.983571\n",
      "Iteration 11, loss = 0.03632542\n",
      "Validation score: 0.983393\n",
      "Iteration 12, loss = 0.03567402\n",
      "Validation score: 0.980357\n",
      "Iteration 13, loss = 0.03490005\n",
      "Validation score: 0.983571\n",
      "Iteration 14, loss = 0.03227332\n",
      "Validation score: 0.983393\n",
      "Iteration 15, loss = 0.03172489\n",
      "Validation score: 0.982321\n",
      "Iteration 16, loss = 0.03074304\n",
      "Validation score: 0.983571\n",
      "Iteration 17, loss = 0.03088784\n",
      "Validation score: 0.984643\n",
      "Iteration 18, loss = 0.02966297\n",
      "Validation score: 0.981964\n",
      "Iteration 19, loss = 0.03161946\n",
      "Validation score: 0.985179\n",
      "Iteration 20, loss = 0.03194024\n",
      "Validation score: 0.982143\n",
      "Iteration 21, loss = 0.03324775\n",
      "Validation score: 0.981964\n",
      "Iteration 22, loss = 0.02839516\n",
      "Validation score: 0.985000\n",
      "Iteration 23, loss = 0.02561547\n",
      "Validation score: 0.984107\n",
      "Iteration 24, loss = 0.02557135\n",
      "Validation score: 0.984286\n",
      "Iteration 25, loss = 0.02475555\n",
      "Validation score: 0.982143\n",
      "Iteration 26, loss = 0.03793917\n",
      "Validation score: 0.974821\n",
      "Iteration 27, loss = 0.03301401\n",
      "Validation score: 0.980357\n",
      "Iteration 28, loss = 0.02854639\n",
      "Validation score: 0.982679\n",
      "Iteration 29, loss = 0.02480768\n",
      "Validation score: 0.983929\n",
      "Iteration 30, loss = 0.02269713\n",
      "Validation score: 0.984821\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(500,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(500,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9974464285714286\n",
      "\n",
      "Test Accuracy:  0.9788571428571429\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_500 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_500)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_500 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30947555\n",
      "Validation score: 0.956250\n",
      "Iteration 2, loss = 0.13865780\n",
      "Validation score: 0.965179\n",
      "Iteration 3, loss = 0.09792018\n",
      "Validation score: 0.973750\n",
      "Iteration 4, loss = 0.07638223\n",
      "Validation score: 0.978750\n",
      "Iteration 5, loss = 0.06454135\n",
      "Validation score: 0.976607\n",
      "Iteration 6, loss = 0.05535012\n",
      "Validation score: 0.980179\n",
      "Iteration 7, loss = 0.04874788\n",
      "Validation score: 0.979643\n",
      "Iteration 8, loss = 0.04286844\n",
      "Validation score: 0.977679\n",
      "Iteration 9, loss = 0.04114738\n",
      "Validation score: 0.977500\n",
      "Iteration 10, loss = 0.04031664\n",
      "Validation score: 0.979643\n",
      "Iteration 11, loss = 0.03750210\n",
      "Validation score: 0.978929\n",
      "Iteration 12, loss = 0.03673160\n",
      "Validation score: 0.979643\n",
      "Iteration 13, loss = 0.03591200\n",
      "Validation score: 0.979643\n",
      "Iteration 14, loss = 0.03430436\n",
      "Validation score: 0.980536\n",
      "Iteration 15, loss = 0.03423258\n",
      "Validation score: 0.978393\n",
      "Iteration 16, loss = 0.03442608\n",
      "Validation score: 0.978929\n",
      "Iteration 17, loss = 0.03694579\n",
      "Validation score: 0.980000\n",
      "Iteration 18, loss = 0.03381956\n",
      "Validation score: 0.980893\n",
      "Iteration 19, loss = 0.03097448\n",
      "Validation score: 0.979464\n",
      "Iteration 20, loss = 0.03592384\n",
      "Validation score: 0.979286\n",
      "Iteration 21, loss = 0.03115669\n",
      "Validation score: 0.982321\n",
      "Iteration 22, loss = 0.02895088\n",
      "Validation score: 0.981250\n",
      "Iteration 23, loss = 0.03070211\n",
      "Validation score: 0.978214\n",
      "Iteration 24, loss = 0.03565202\n",
      "Validation score: 0.979286\n",
      "Iteration 25, loss = 0.03712672\n",
      "Validation score: 0.981786\n",
      "Iteration 26, loss = 0.03105706\n",
      "Validation score: 0.981071\n",
      "Iteration 27, loss = 0.02708505\n",
      "Validation score: 0.981429\n",
      "Iteration 28, loss = 0.02443519\n",
      "Validation score: 0.984286\n",
      "Iteration 29, loss = 0.02585180\n",
      "Validation score: 0.976607\n",
      "Iteration 30, loss = 0.04283548\n",
      "Validation score: 0.980000\n",
      "Iteration 31, loss = 0.03427169\n",
      "Validation score: 0.980357\n",
      "Iteration 32, loss = 0.02801654\n",
      "Validation score: 0.983214\n",
      "Iteration 33, loss = 0.02494689\n",
      "Validation score: 0.982679\n",
      "Iteration 34, loss = 0.02305160\n",
      "Validation score: 0.983036\n",
      "Iteration 35, loss = 0.02359134\n",
      "Validation score: 0.976964\n",
      "Iteration 36, loss = 0.04044203\n",
      "Validation score: 0.980536\n",
      "Iteration 37, loss = 0.03406462\n",
      "Validation score: 0.982679\n",
      "Iteration 38, loss = 0.02692168\n",
      "Validation score: 0.982679\n",
      "Iteration 39, loss = 0.02324482\n",
      "Validation score: 0.982500\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 9min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(1000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(1000,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9983571428571428\n",
      "\n",
      "Test Accuracy:  0.9832857142857143\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_1000 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_1000)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_1000 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.28722117\n",
      "Validation score: 0.962500\n",
      "Iteration 2, loss = 0.12345537\n",
      "Validation score: 0.973571\n",
      "Iteration 3, loss = 0.08975509\n",
      "Validation score: 0.975536\n",
      "Iteration 4, loss = 0.07200716\n",
      "Validation score: 0.980536\n",
      "Iteration 5, loss = 0.06105332\n",
      "Validation score: 0.978214\n",
      "Iteration 6, loss = 0.05452200\n",
      "Validation score: 0.977857\n",
      "Iteration 7, loss = 0.04893191\n",
      "Validation score: 0.980893\n",
      "Iteration 8, loss = 0.04568876\n",
      "Validation score: 0.983214\n",
      "Iteration 9, loss = 0.04341551\n",
      "Validation score: 0.983750\n",
      "Iteration 10, loss = 0.04421476\n",
      "Validation score: 0.981607\n",
      "Iteration 11, loss = 0.04220098\n",
      "Validation score: 0.978571\n",
      "Iteration 12, loss = 0.04581884\n",
      "Validation score: 0.979286\n",
      "Iteration 13, loss = 0.04089177\n",
      "Validation score: 0.980357\n",
      "Iteration 14, loss = 0.04065214\n",
      "Validation score: 0.980179\n",
      "Iteration 15, loss = 0.03974234\n",
      "Validation score: 0.980000\n",
      "Iteration 16, loss = 0.03955291\n",
      "Validation score: 0.983393\n",
      "Iteration 17, loss = 0.03967063\n",
      "Validation score: 0.980536\n",
      "Iteration 18, loss = 0.03925396\n",
      "Validation score: 0.979821\n",
      "Iteration 19, loss = 0.03715362\n",
      "Validation score: 0.980179\n",
      "Iteration 20, loss = 0.03930785\n",
      "Validation score: 0.983214\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 9min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(2000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(2000,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9957321428571428\n",
      "\n",
      "Test Accuracy:  0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_2000 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_2000)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_2000 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer = 1; Neurons = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.25357017\n",
      "Validation score: 0.967857\n",
      "Iteration 2, loss = 0.11546254\n",
      "Validation score: 0.970714\n",
      "Iteration 3, loss = 0.08745436\n",
      "Validation score: 0.972679\n",
      "Iteration 4, loss = 0.07510534\n",
      "Validation score: 0.974821\n",
      "Iteration 5, loss = 0.06612306\n",
      "Validation score: 0.976429\n",
      "Iteration 6, loss = 0.06064331\n",
      "Validation score: 0.977500\n",
      "Iteration 7, loss = 0.05801994\n",
      "Validation score: 0.978393\n",
      "Iteration 8, loss = 0.06019180\n",
      "Validation score: 0.975714\n",
      "Iteration 9, loss = 0.05840026\n",
      "Validation score: 0.976964\n",
      "Iteration 10, loss = 0.05452443\n",
      "Validation score: 0.978750\n",
      "Iteration 11, loss = 0.05723096\n",
      "Validation score: 0.978393\n",
      "Iteration 12, loss = 0.05264961\n",
      "Validation score: 0.978393\n",
      "Iteration 13, loss = 0.05176128\n",
      "Validation score: 0.981429\n",
      "Iteration 14, loss = 0.04863848\n",
      "Validation score: 0.980179\n",
      "Iteration 15, loss = 0.04661380\n",
      "Validation score: 0.978929\n",
      "Iteration 16, loss = 0.04775651\n",
      "Validation score: 0.980357\n",
      "Iteration 17, loss = 0.04493079\n",
      "Validation score: 0.980714\n",
      "Iteration 18, loss = 0.04469384\n",
      "Validation score: 0.976607\n",
      "Iteration 19, loss = 0.04592337\n",
      "Validation score: 0.978750\n",
      "Iteration 20, loss = 0.04395668\n",
      "Validation score: 0.982857\n",
      "Iteration 21, loss = 0.04093998\n",
      "Validation score: 0.979821\n",
      "Iteration 22, loss = 0.03763000\n",
      "Validation score: 0.983036\n",
      "Iteration 23, loss = 0.04134503\n",
      "Validation score: 0.979107\n",
      "Iteration 24, loss = 0.03954499\n",
      "Validation score: 0.979464\n",
      "Iteration 25, loss = 0.03522699\n",
      "Validation score: 0.977143\n",
      "Iteration 26, loss = 0.03688767\n",
      "Validation score: 0.981071\n",
      "Iteration 27, loss = 0.04027077\n",
      "Validation score: 0.980179\n",
      "Iteration 28, loss = 0.03615005\n",
      "Validation score: 0.982143\n",
      "Iteration 29, loss = 0.03316162\n",
      "Validation score: 0.978393\n",
      "Iteration 30, loss = 0.03506783\n",
      "Validation score: 0.977143\n",
      "Iteration 31, loss = 0.03717584\n",
      "Validation score: 0.980536\n",
      "Iteration 32, loss = 0.03106656\n",
      "Validation score: 0.982143\n",
      "Iteration 33, loss = 0.03040024\n",
      "Validation score: 0.981071\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 41min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(5000,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9975357142857143\n",
      "\n",
      "Test Accuracy:  0.9831428571428571\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_onehiddenlayer_5000 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_onehiddenlayer_5000)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_onehiddenlayer_5000 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_onehiddenlayer_5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 2; Neurons = (200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37100682\n",
      "Validation score: 0.944464\n",
      "Iteration 2, loss = 0.15331098\n",
      "Validation score: 0.964464\n",
      "Iteration 3, loss = 0.10969901\n",
      "Validation score: 0.969286\n",
      "Iteration 4, loss = 0.08368030\n",
      "Validation score: 0.971964\n",
      "Iteration 5, loss = 0.06764082\n",
      "Validation score: 0.975179\n",
      "Iteration 6, loss = 0.05593642\n",
      "Validation score: 0.976786\n",
      "Iteration 7, loss = 0.05019062\n",
      "Validation score: 0.975179\n",
      "Iteration 8, loss = 0.04260343\n",
      "Validation score: 0.978036\n",
      "Iteration 9, loss = 0.03668269\n",
      "Validation score: 0.980000\n",
      "Iteration 10, loss = 0.03416973\n",
      "Validation score: 0.976786\n",
      "Iteration 11, loss = 0.03293507\n",
      "Validation score: 0.978393\n",
      "Iteration 12, loss = 0.03036566\n",
      "Validation score: 0.977500\n",
      "Iteration 13, loss = 0.02924157\n",
      "Validation score: 0.978750\n",
      "Iteration 14, loss = 0.02737091\n",
      "Validation score: 0.979107\n",
      "Iteration 15, loss = 0.02828488\n",
      "Validation score: 0.975000\n",
      "Iteration 16, loss = 0.02816211\n",
      "Validation score: 0.973929\n",
      "Iteration 17, loss = 0.02912006\n",
      "Validation score: 0.978393\n",
      "Iteration 18, loss = 0.02355310\n",
      "Validation score: 0.977857\n",
      "Iteration 19, loss = 0.02611316\n",
      "Validation score: 0.979107\n",
      "Iteration 20, loss = 0.02096315\n",
      "Validation score: 0.982143\n",
      "Iteration 21, loss = 0.02053775\n",
      "Validation score: 0.980179\n",
      "Iteration 22, loss = 0.03373370\n",
      "Validation score: 0.977143\n",
      "Iteration 23, loss = 0.03147340\n",
      "Validation score: 0.976071\n",
      "Iteration 24, loss = 0.02384761\n",
      "Validation score: 0.976786\n",
      "Iteration 25, loss = 0.02165176\n",
      "Validation score: 0.979286\n",
      "Iteration 26, loss = 0.02223391\n",
      "Validation score: 0.981071\n",
      "Iteration 27, loss = 0.02413602\n",
      "Validation score: 0.979107\n",
      "Iteration 28, loss = 0.02897629\n",
      "Validation score: 0.976250\n",
      "Iteration 29, loss = 0.02501661\n",
      "Validation score: 0.978036\n",
      "Iteration 30, loss = 0.02215351\n",
      "Validation score: 0.981964\n",
      "Iteration 31, loss = 0.02319395\n",
      "Validation score: 0.976786\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(200,100), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9981785714285715\n",
      "\n",
      "Test Accuracy:  0.9812142857142857\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_1 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_1)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_1 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 2; Neurons = (300, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.33372837\n",
      "Validation score: 0.958393\n",
      "Iteration 2, loss = 0.13647309\n",
      "Validation score: 0.966429\n",
      "Iteration 3, loss = 0.09455731\n",
      "Validation score: 0.972143\n",
      "Iteration 4, loss = 0.07341847\n",
      "Validation score: 0.976607\n",
      "Iteration 5, loss = 0.05972278\n",
      "Validation score: 0.977679\n",
      "Iteration 6, loss = 0.05096557\n",
      "Validation score: 0.978571\n",
      "Iteration 7, loss = 0.04259430\n",
      "Validation score: 0.976607\n",
      "Iteration 8, loss = 0.03850109\n",
      "Validation score: 0.979821\n",
      "Iteration 9, loss = 0.03798578\n",
      "Validation score: 0.980000\n",
      "Iteration 10, loss = 0.03528988\n",
      "Validation score: 0.979821\n",
      "Iteration 11, loss = 0.03419344\n",
      "Validation score: 0.977857\n",
      "Iteration 12, loss = 0.03449891\n",
      "Validation score: 0.983571\n",
      "Iteration 13, loss = 0.02966569\n",
      "Validation score: 0.984107\n",
      "Iteration 14, loss = 0.03349260\n",
      "Validation score: 0.978393\n",
      "Iteration 15, loss = 0.03365905\n",
      "Validation score: 0.982500\n",
      "Iteration 16, loss = 0.02815348\n",
      "Validation score: 0.982143\n",
      "Iteration 17, loss = 0.02699058\n",
      "Validation score: 0.984107\n",
      "Iteration 18, loss = 0.02740754\n",
      "Validation score: 0.981964\n",
      "Iteration 19, loss = 0.03185487\n",
      "Validation score: 0.976607\n",
      "Iteration 20, loss = 0.03463432\n",
      "Validation score: 0.978393\n",
      "Iteration 21, loss = 0.03111342\n",
      "Validation score: 0.980536\n",
      "Iteration 22, loss = 0.02846399\n",
      "Validation score: 0.977679\n",
      "Iteration 23, loss = 0.02447215\n",
      "Validation score: 0.981607\n",
      "Iteration 24, loss = 0.02155838\n",
      "Validation score: 0.984643\n",
      "Iteration 25, loss = 0.01977458\n",
      "Validation score: 0.984643\n",
      "Iteration 26, loss = 0.01847701\n",
      "Validation score: 0.985893\n",
      "Iteration 27, loss = 0.01736975\n",
      "Validation score: 0.985536\n",
      "Iteration 28, loss = 0.03272767\n",
      "Validation score: 0.967321\n",
      "Iteration 29, loss = 0.04766578\n",
      "Validation score: 0.980000\n",
      "Iteration 30, loss = 0.02913394\n",
      "Validation score: 0.984107\n",
      "Iteration 31, loss = 0.02615021\n",
      "Validation score: 0.983393\n",
      "Iteration 32, loss = 0.02406520\n",
      "Validation score: 0.984643\n",
      "Iteration 33, loss = 0.02089256\n",
      "Validation score: 0.986607\n",
      "Iteration 34, loss = 0.01857043\n",
      "Validation score: 0.988036\n",
      "Iteration 35, loss = 0.01722872\n",
      "Validation score: 0.986786\n",
      "Iteration 36, loss = 0.01615747\n",
      "Validation score: 0.986429\n",
      "Iteration 37, loss = 0.01754557\n",
      "Validation score: 0.980000\n",
      "Iteration 38, loss = 0.04472028\n",
      "Validation score: 0.979821\n",
      "Iteration 39, loss = 0.02992698\n",
      "Validation score: 0.983929\n",
      "Iteration 40, loss = 0.02276644\n",
      "Validation score: 0.980357\n",
      "Iteration 41, loss = 0.02115256\n",
      "Validation score: 0.984643\n",
      "Iteration 42, loss = 0.01873456\n",
      "Validation score: 0.983036\n",
      "Iteration 43, loss = 0.01678978\n",
      "Validation score: 0.985893\n",
      "Iteration 44, loss = 0.01571695\n",
      "Validation score: 0.985536\n",
      "Iteration 45, loss = 0.01488077\n",
      "Validation score: 0.985714\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 3min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300, 200), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(300,200), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9987857142857143\n",
      "\n",
      "Test Accuracy:  0.9842857142857143\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_2 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_2)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_2 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 3; Neurons = (300, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32578472\n",
      "Validation score: 0.958571\n",
      "Iteration 2, loss = 0.12857676\n",
      "Validation score: 0.971071\n",
      "Iteration 3, loss = 0.09145311\n",
      "Validation score: 0.974107\n",
      "Iteration 4, loss = 0.07035571\n",
      "Validation score: 0.978214\n",
      "Iteration 5, loss = 0.05900383\n",
      "Validation score: 0.980536\n",
      "Iteration 6, loss = 0.05090066\n",
      "Validation score: 0.975714\n",
      "Iteration 7, loss = 0.05141608\n",
      "Validation score: 0.978393\n",
      "Iteration 8, loss = 0.04430007\n",
      "Validation score: 0.979286\n",
      "Iteration 9, loss = 0.04055200\n",
      "Validation score: 0.977143\n",
      "Iteration 10, loss = 0.03681570\n",
      "Validation score: 0.978393\n",
      "Iteration 11, loss = 0.03706960\n",
      "Validation score: 0.977143\n",
      "Iteration 12, loss = 0.03556225\n",
      "Validation score: 0.974643\n",
      "Iteration 13, loss = 0.03687039\n",
      "Validation score: 0.976964\n",
      "Iteration 14, loss = 0.03563277\n",
      "Validation score: 0.970536\n",
      "Iteration 15, loss = 0.03702560\n",
      "Validation score: 0.976429\n",
      "Iteration 16, loss = 0.03450430\n",
      "Validation score: 0.975536\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(300, 200, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(300,200,100), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9919464285714286\n",
      "\n",
      "Test Accuracy:  0.9772857142857143\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_3 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_3)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_3 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 4; Neurons = (400, 300, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32364003\n",
      "Validation score: 0.960714\n",
      "Iteration 2, loss = 0.12928598\n",
      "Validation score: 0.966429\n",
      "Iteration 3, loss = 0.09555929\n",
      "Validation score: 0.973036\n",
      "Iteration 4, loss = 0.07802366\n",
      "Validation score: 0.973036\n",
      "Iteration 5, loss = 0.06514605\n",
      "Validation score: 0.965179\n",
      "Iteration 6, loss = 0.05664391\n",
      "Validation score: 0.972500\n",
      "Iteration 7, loss = 0.05556226\n",
      "Validation score: 0.975179\n",
      "Iteration 8, loss = 0.05511449\n",
      "Validation score: 0.976429\n",
      "Iteration 9, loss = 0.04900147\n",
      "Validation score: 0.971786\n",
      "Iteration 10, loss = 0.04600217\n",
      "Validation score: 0.976964\n",
      "Iteration 11, loss = 0.04895063\n",
      "Validation score: 0.975536\n",
      "Iteration 12, loss = 0.04737209\n",
      "Validation score: 0.979107\n",
      "Iteration 13, loss = 0.04108417\n",
      "Validation score: 0.978929\n",
      "Iteration 14, loss = 0.04750174\n",
      "Validation score: 0.973214\n",
      "Iteration 15, loss = 0.04617567\n",
      "Validation score: 0.979107\n",
      "Iteration 16, loss = 0.04150203\n",
      "Validation score: 0.978929\n",
      "Iteration 17, loss = 0.03970768\n",
      "Validation score: 0.975893\n",
      "Iteration 18, loss = 0.04212191\n",
      "Validation score: 0.975714\n",
      "Iteration 19, loss = 0.04273725\n",
      "Validation score: 0.975000\n",
      "Iteration 20, loss = 0.04155361\n",
      "Validation score: 0.977500\n",
      "Iteration 21, loss = 0.03805262\n",
      "Validation score: 0.974464\n",
      "Iteration 22, loss = 0.04074504\n",
      "Validation score: 0.979107\n",
      "Iteration 23, loss = 0.04141658\n",
      "Validation score: 0.977143\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(400, 300, 200, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(400,300,200,100), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9956071428571428\n",
      "\n",
      "Test Accuracy:  0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_4 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_4)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_4 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 5; Neurons = (500, 400, 300, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32686401\n",
      "Validation score: 0.960893\n",
      "Iteration 2, loss = 0.13652660\n",
      "Validation score: 0.967500\n",
      "Iteration 3, loss = 0.10428899\n",
      "Validation score: 0.977321\n",
      "Iteration 4, loss = 0.08798424\n",
      "Validation score: 0.974464\n",
      "Iteration 5, loss = 0.08025828\n",
      "Validation score: 0.977143\n",
      "Iteration 6, loss = 0.07131471\n",
      "Validation score: 0.975536\n",
      "Iteration 7, loss = 0.06801173\n",
      "Validation score: 0.977679\n",
      "Iteration 8, loss = 0.06521738\n",
      "Validation score: 0.972500\n",
      "Iteration 9, loss = 0.06195226\n",
      "Validation score: 0.974821\n",
      "Iteration 10, loss = 0.06379278\n",
      "Validation score: 0.976071\n",
      "Iteration 11, loss = 0.06136027\n",
      "Validation score: 0.977679\n",
      "Iteration 12, loss = 0.05853017\n",
      "Validation score: 0.975714\n",
      "Iteration 13, loss = 0.05661618\n",
      "Validation score: 0.978750\n",
      "Iteration 14, loss = 0.05344887\n",
      "Validation score: 0.980536\n",
      "Iteration 15, loss = 0.05478905\n",
      "Validation score: 0.978571\n",
      "Iteration 16, loss = 0.05535842\n",
      "Validation score: 0.978214\n",
      "Iteration 17, loss = 0.05373343\n",
      "Validation score: 0.975179\n",
      "Iteration 18, loss = 0.05092989\n",
      "Validation score: 0.978929\n",
      "Iteration 19, loss = 0.05019458\n",
      "Validation score: 0.978393\n",
      "Iteration 20, loss = 0.05297038\n",
      "Validation score: 0.979286\n",
      "Iteration 21, loss = 0.04876767\n",
      "Validation score: 0.980000\n",
      "Iteration 22, loss = 0.05253626\n",
      "Validation score: 0.979464\n",
      "Iteration 23, loss = 0.04850841\n",
      "Validation score: 0.979107\n",
      "Iteration 24, loss = 0.04811297\n",
      "Validation score: 0.979107\n",
      "Iteration 25, loss = 0.04869332\n",
      "Validation score: 0.980893\n",
      "Iteration 26, loss = 0.04791537\n",
      "Validation score: 0.980000\n",
      "Iteration 27, loss = 0.04527093\n",
      "Validation score: 0.979286\n",
      "Iteration 28, loss = 0.04367835\n",
      "Validation score: 0.981786\n",
      "Iteration 29, loss = 0.03902916\n",
      "Validation score: 0.977321\n",
      "Iteration 30, loss = 0.04807961\n",
      "Validation score: 0.975357\n",
      "Iteration 31, loss = 0.04586593\n",
      "Validation score: 0.980000\n",
      "Iteration 32, loss = 0.04071711\n",
      "Validation score: 0.980893\n",
      "Iteration 33, loss = 0.04004606\n",
      "Validation score: 0.981964\n",
      "Iteration 34, loss = 0.03827428\n",
      "Validation score: 0.979107\n",
      "Iteration 35, loss = 0.04017414\n",
      "Validation score: 0.977500\n",
      "Iteration 36, loss = 0.04167464\n",
      "Validation score: 0.983750\n",
      "Iteration 37, loss = 0.03829742\n",
      "Validation score: 0.978929\n",
      "Iteration 38, loss = 0.04261723\n",
      "Validation score: 0.981429\n",
      "Iteration 39, loss = 0.03508334\n",
      "Validation score: 0.982321\n",
      "Iteration 40, loss = 0.03691995\n",
      "Validation score: 0.975000\n",
      "Iteration 41, loss = 0.03645832\n",
      "Validation score: 0.979107\n",
      "Iteration 42, loss = 0.03724283\n",
      "Validation score: 0.981429\n",
      "Iteration 43, loss = 0.03691844\n",
      "Validation score: 0.979643\n",
      "Iteration 44, loss = 0.03631424\n",
      "Validation score: 0.982143\n",
      "Iteration 45, loss = 0.03583734\n",
      "Validation score: 0.981786\n",
      "Iteration 46, loss = 0.03422403\n",
      "Validation score: 0.975357\n",
      "Iteration 47, loss = 0.03460161\n",
      "Validation score: 0.976429\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 10min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(500, 400, 300, 200, 100),\n",
       "              learning_rate='constant', learning_rate_init=0.001, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
       "              tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(500,400,300,200,100), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9975892857142857\n",
      "\n",
      "Test Accuracy:  0.9827142857142858\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_5 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_5)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_5 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 6; Neurons = (1000, 500, 400, 300, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.33923566\n",
      "Validation score: 0.961607\n",
      "Iteration 2, loss = 0.14722758\n",
      "Validation score: 0.965893\n",
      "Iteration 3, loss = 0.11934753\n",
      "Validation score: 0.971607\n",
      "Iteration 4, loss = 0.10406398\n",
      "Validation score: 0.973929\n",
      "Iteration 5, loss = 0.09670969\n",
      "Validation score: 0.972500\n",
      "Iteration 6, loss = 0.09080314\n",
      "Validation score: 0.975179\n",
      "Iteration 7, loss = 0.08073741\n",
      "Validation score: 0.974107\n",
      "Iteration 8, loss = 0.08058210\n",
      "Validation score: 0.976071\n",
      "Iteration 9, loss = 0.07939734\n",
      "Validation score: 0.978571\n",
      "Iteration 10, loss = 0.07659585\n",
      "Validation score: 0.977500\n",
      "Iteration 11, loss = 0.07390236\n",
      "Validation score: 0.977321\n",
      "Iteration 12, loss = 0.07103932\n",
      "Validation score: 0.979286\n",
      "Iteration 13, loss = 0.06750114\n",
      "Validation score: 0.980000\n",
      "Iteration 14, loss = 0.06460772\n",
      "Validation score: 0.979107\n",
      "Iteration 15, loss = 0.06517882\n",
      "Validation score: 0.981250\n",
      "Iteration 16, loss = 0.06411654\n",
      "Validation score: 0.978393\n",
      "Iteration 17, loss = 0.06271576\n",
      "Validation score: 0.979107\n",
      "Iteration 18, loss = 0.05841112\n",
      "Validation score: 0.977500\n",
      "Iteration 19, loss = 0.05866026\n",
      "Validation score: 0.981250\n",
      "Iteration 20, loss = 0.05757321\n",
      "Validation score: 0.977857\n",
      "Iteration 21, loss = 0.05854191\n",
      "Validation score: 0.979464\n",
      "Iteration 22, loss = 0.05821794\n",
      "Validation score: 0.978393\n",
      "Iteration 23, loss = 0.05446351\n",
      "Validation score: 0.979464\n",
      "Iteration 24, loss = 0.05201080\n",
      "Validation score: 0.981071\n",
      "Iteration 25, loss = 0.05214284\n",
      "Validation score: 0.980893\n",
      "Iteration 26, loss = 0.04936134\n",
      "Validation score: 0.975000\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 14min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(1000, 500, 400, 300, 200, 100),\n",
       "              learning_rate='constant', learning_rate_init=0.001, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
       "              tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(1000,500,400,300,200,100), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9953392857142858\n",
      "\n",
      "Test Accuracy:  0.9802857142857143\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_6 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_6)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_6 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 2; Neurons = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.36495484\n",
      "Validation score: 0.949821\n",
      "Iteration 2, loss = 0.14276405\n",
      "Validation score: 0.961964\n",
      "Iteration 3, loss = 0.10075009\n",
      "Validation score: 0.969286\n",
      "Iteration 4, loss = 0.07928685\n",
      "Validation score: 0.971429\n",
      "Iteration 5, loss = 0.06495611\n",
      "Validation score: 0.970000\n",
      "Iteration 6, loss = 0.05641086\n",
      "Validation score: 0.972143\n",
      "Iteration 7, loss = 0.04947723\n",
      "Validation score: 0.969643\n",
      "Iteration 8, loss = 0.04421112\n",
      "Validation score: 0.975714\n",
      "Iteration 9, loss = 0.03980373\n",
      "Validation score: 0.973571\n",
      "Iteration 10, loss = 0.03421165\n",
      "Validation score: 0.975179\n",
      "Iteration 11, loss = 0.03316332\n",
      "Validation score: 0.976607\n",
      "Iteration 12, loss = 0.03145377\n",
      "Validation score: 0.972679\n",
      "Iteration 13, loss = 0.03080832\n",
      "Validation score: 0.976071\n",
      "Iteration 14, loss = 0.03164143\n",
      "Validation score: 0.977143\n",
      "Iteration 15, loss = 0.02985800\n",
      "Validation score: 0.976607\n",
      "Iteration 16, loss = 0.02814414\n",
      "Validation score: 0.975357\n",
      "Iteration 17, loss = 0.02824576\n",
      "Validation score: 0.976250\n",
      "Iteration 18, loss = 0.02823447\n",
      "Validation score: 0.975179\n",
      "Iteration 19, loss = 0.03087562\n",
      "Validation score: 0.975000\n",
      "Iteration 20, loss = 0.02534153\n",
      "Validation score: 0.976607\n",
      "Iteration 21, loss = 0.02749774\n",
      "Validation score: 0.975000\n",
      "Iteration 22, loss = 0.03094196\n",
      "Validation score: 0.974107\n",
      "Iteration 23, loss = 0.02735067\n",
      "Validation score: 0.977321\n",
      "Iteration 24, loss = 0.02489001\n",
      "Validation score: 0.977500\n",
      "Iteration 25, loss = 0.02460725\n",
      "Validation score: 0.976429\n",
      "Iteration 26, loss = 0.02157557\n",
      "Validation score: 0.980000\n",
      "Iteration 27, loss = 0.02019737\n",
      "Validation score: 0.974643\n",
      "Iteration 28, loss = 0.03686266\n",
      "Validation score: 0.979286\n",
      "Iteration 29, loss = 0.02871790\n",
      "Validation score: 0.978571\n",
      "Iteration 30, loss = 0.02787135\n",
      "Validation score: 0.978571\n",
      "Iteration 31, loss = 0.02281343\n",
      "Validation score: 0.979821\n",
      "Iteration 32, loss = 0.01989833\n",
      "Validation score: 0.980536\n",
      "Iteration 33, loss = 0.01849016\n",
      "Validation score: 0.981071\n",
      "Iteration 34, loss = 0.01733534\n",
      "Validation score: 0.981786\n",
      "Iteration 35, loss = 0.01646152\n",
      "Validation score: 0.981429\n",
      "Iteration 36, loss = 0.02402260\n",
      "Validation score: 0.974643\n",
      "Iteration 37, loss = 0.04190810\n",
      "Validation score: 0.977321\n",
      "Iteration 38, loss = 0.02428367\n",
      "Validation score: 0.979286\n",
      "Iteration 39, loss = 0.02032903\n",
      "Validation score: 0.978393\n",
      "Iteration 40, loss = 0.01827422\n",
      "Validation score: 0.981607\n",
      "Iteration 41, loss = 0.01675611\n",
      "Validation score: 0.980893\n",
      "Iteration 42, loss = 0.01598394\n",
      "Validation score: 0.980893\n",
      "Iteration 43, loss = 0.01564059\n",
      "Validation score: 0.980714\n",
      "Iteration 44, loss = 0.03661580\n",
      "Validation score: 0.973393\n",
      "Iteration 45, loss = 0.03001303\n",
      "Validation score: 0.979107\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(200,200,), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9981785714285715\n",
      "\n",
      "Test Accuracy:  0.9828571428571429\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_7 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_7)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_7 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers = 2; Neurons = (200, 200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.33766184\n",
      "Validation score: 0.948750\n",
      "Iteration 2, loss = 0.13272727\n",
      "Validation score: 0.963750\n",
      "Iteration 3, loss = 0.09475740\n",
      "Validation score: 0.966429\n",
      "Iteration 4, loss = 0.07354296\n",
      "Validation score: 0.971786\n",
      "Iteration 5, loss = 0.05974406\n",
      "Validation score: 0.969643\n",
      "Iteration 6, loss = 0.05673193\n",
      "Validation score: 0.963571\n",
      "Iteration 7, loss = 0.04775784\n",
      "Validation score: 0.977500\n",
      "Iteration 8, loss = 0.04071493\n",
      "Validation score: 0.972679\n",
      "Iteration 9, loss = 0.04059401\n",
      "Validation score: 0.975000\n",
      "Iteration 10, loss = 0.03878671\n",
      "Validation score: 0.975893\n",
      "Iteration 11, loss = 0.03583292\n",
      "Validation score: 0.975357\n",
      "Iteration 12, loss = 0.03679866\n",
      "Validation score: 0.973393\n",
      "Iteration 13, loss = 0.03746589\n",
      "Validation score: 0.975536\n",
      "Iteration 14, loss = 0.03279575\n",
      "Validation score: 0.973929\n",
      "Iteration 15, loss = 0.03797293\n",
      "Validation score: 0.974643\n",
      "Iteration 16, loss = 0.03109364\n",
      "Validation score: 0.974821\n",
      "Iteration 17, loss = 0.03298044\n",
      "Validation score: 0.974286\n",
      "Iteration 18, loss = 0.03286224\n",
      "Validation score: 0.974643\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(200, 200, 200), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(200,200,200), max_iter=1000, alpha=0.01,\n",
    "                    solver='adam', verbose=True, tol=1e-5, random_state=1, \n",
    "                    learning_rate = 'constant', learning_rate_init=0.001, activation='relu',\n",
    "                    early_stopping=True, n_iter_no_change=10)\n",
    "\n",
    "mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.994125\n",
      "\n",
      "Test Accuracy:  0.9777857142857143\n"
     ]
    }
   ],
   "source": [
    "y_train_predicted = mlp_clf.predict(X_train)\n",
    "\n",
    "train_accuracy_twohiddenlayers_8 = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_twohiddenlayers_8)\n",
    "\n",
    "\n",
    "y_test_predicted = mlp_clf.predict(X_test)\n",
    "\n",
    "test_accuracy_twohiddenlayers_8 = np.mean(y_test_predicted == y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_twohiddenlayers_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.977071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.980857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.978857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.983286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.978571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.983143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>(200, 100)</td>\n",
       "      <td>0.981214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>0.982857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>(300, 200)</td>\n",
       "      <td>0.984286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>(300, 200, 100)</td>\n",
       "      <td>0.977286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>(200, 200, 200)</td>\n",
       "      <td>0.977786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>(400, 300, 200, 100)</td>\n",
       "      <td>0.978571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>(500, 400, 300, 200, 100)</td>\n",
       "      <td>0.982714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>(1000, 500, 400, 300, 200, 100)</td>\n",
       "      <td>0.980286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hidden Layers                          Neurons  Accuracy\n",
       "0               1                              100  0.977071\n",
       "1               1                              200  0.980857\n",
       "2               1                              500  0.978857\n",
       "3               1                             1000  0.983286\n",
       "4               1                             2000  0.978571\n",
       "5               1                             5000  0.983143\n",
       "6               2                       (200, 100)  0.981214\n",
       "7               2                       (200, 200)  0.982857\n",
       "8               2                       (300, 200)  0.984286\n",
       "9               3                  (300, 200, 100)  0.977286\n",
       "10              3                  (200, 200, 200)  0.977786\n",
       "11              4             (400, 300, 200, 100)  0.978571\n",
       "12              5        (500, 400, 300, 200, 100)  0.982714\n",
       "13              6  (1000, 500, 400, 300, 200, 100)  0.980286"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 100, test_accuracy_onehiddenlayer_100],\n",
    "        [1, 200, test_accuracy_onehiddenlayer_200],\n",
    "        [1, 500, test_accuracy_onehiddenlayer_500],\n",
    "        [1, 1000, test_accuracy_onehiddenlayer_1000],\n",
    "        [1, 2000, test_accuracy_onehiddenlayer_2000],\n",
    "        [1, 5000, test_accuracy_onehiddenlayer_5000],\n",
    "        [2, (200, 100), test_accuracy_twohiddenlayers_1],\n",
    "        [2, (200, 200), test_accuracy_twohiddenlayers_7],\n",
    "        [2, (300, 200), test_accuracy_twohiddenlayers_2],\n",
    "        [3, (300, 200, 100), test_accuracy_twohiddenlayers_3],\n",
    "        [3, (200, 200, 200), test_accuracy_twohiddenlayers_8],\n",
    "        [4, (400, 300, 200, 100), test_accuracy_twohiddenlayers_4],\n",
    "        [5, (500, 400, 300, 200, 100), test_accuracy_twohiddenlayers_5],\n",
    "        [6, (1000, 500, 400, 300, 200, 100), test_accuracy_twohiddenlayers_6]]\n",
    "pd.DataFrame(data, columns=[\"Hidden Layers\", \"Neurons\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "We observe that the MLP with **two hidden layers containing 300 and 200 neurons**, respetively performs the best (test accuracy = 0.984286).\n",
    "\n",
    "However, we achieve similar accuracy (0.980857) by using only one hidden layer with 200 neurons as well.\n",
    "\n",
    "We notice that the six hidden layer based MLP does not perform better than a single hidden layer (200 neurons) based MLP. It starts to show some **overfitting**. The training time for this heavy MLP architecture is significantly large (14 min vs. 4 min).\n",
    "\n",
    "Thus, to create an optimal or near-optimal architecture for a MLP we should start with simple architectures, then gradually increase its complexity. It is never a good idea to start with a heavy architecture. The heavy architectures are prone to overfitting and expensive to train."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
